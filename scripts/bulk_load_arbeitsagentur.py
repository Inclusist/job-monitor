#!/usr/bin/env python3
"""
One-time bulk loader for Arbeitsagentur jobs

Aggregates all keyword+location combinations from all users and loads
jobs from the last 30 days for each combination.

Usage:
    python scripts/bulk_load_arbeitsagentur.py          # Interactive mode
    python scripts/bulk_load_arbeitsagentur.py --yes    # Auto-confirm mode
"""

import os
import sys
from pathlib import Path
import argparse
from dotenv import load_dotenv

# Load environment variables first
load_dotenv()

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.database.factory import get_database
from src.database.postgres_cv_operations import PostgresCVManager
from src.database.cv_operations import CVManager
from src.collectors.arbeitsagentur import ArbeitsagenturCollector
import os
from datetime import datetime
import time
from collections import defaultdict
import yaml

def load_config():
    """Load config.yaml for default keywords/locations"""
    config_path = Path(__file__).parent.parent / 'config.yaml'
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)

def get_all_user_combinations(cv_manager):
    """
    Aggregate all unique keyword+location combinations from all users

    Returns:
        dict: {(keyword, location): [user_ids]} mapping
    """
    print("\n" + "="*80)
    print("AGGREGATING SEARCH COMBINATIONS FROM ALL USERS")
    print("="*80)

    # Get all users - need to query database directly
    conn = cv_manager._get_connection()
    cursor = conn.cursor()

    try:
        cursor.execute("SELECT id, email, preferences FROM users WHERE is_active = 1")
        users = cursor.fetchall()
    except:
        # PostgreSQL uses true/false instead of 1/0
        cursor.execute("SELECT id, email, preferences FROM users WHERE is_active = true")
        users = cursor.fetchall()

    cursor.close()

    # Return connection to pool (PostgreSQL) or just close (SQLite)
    if hasattr(cv_manager, '_return_connection'):
        cv_manager._return_connection(conn)
    else:
        conn.close()

    # Load default config
    config = load_config()
    default_keywords = config.get('search_config', {}).get('keywords', [])
    default_locations = config.get('search_config', {}).get('locations', [])

    print(f"\nüìä Found {len(users)} active users")
    print(f"üìã Default config: {len(default_keywords)} keywords, {len(default_locations)} locations")

    # Aggregate combinations
    combinations = defaultdict(list)

    for user in users:
        user_id = user[0]
        user_email = user[1]
        preferences = user[2]

        # Parse preferences
        if preferences:
            if isinstance(preferences, str):
                import json
                try:
                    preferences = json.loads(preferences)
                except:
                    preferences = {}

            keywords = preferences.get('search_keywords', [])
            locations = preferences.get('search_locations', [])
        else:
            keywords = []
            locations = []

        # Fall back to defaults if user has no preferences
        if not keywords:
            keywords = default_keywords
        if not locations:
            locations = default_locations

        print(f"\nüë§ User {user_id} ({user_email})")
        print(f"   Keywords: {', '.join(keywords[:5])}{' ...' if len(keywords) > 5 else ''}")
        print(f"   Locations: {', '.join(locations)}")

        # Add all combinations for this user
        for keyword in keywords:
            for location in locations:
                combinations[(keyword, location)].append(user_id)

    print(f"\n‚úÖ Total unique combinations: {len(combinations)}")
    print("\n" + "="*80)

    return combinations

def bulk_load_jobs(combinations, job_db):
    """
    Load jobs from Arbeitsagentur for all combinations

    Args:
        combinations: dict of {(keyword, location): [user_ids]}
        job_db: Database manager instance
    """
    print("\n" + "="*80)
    print("BULK LOADING JOBS FROM ARBEITSAGENTUR")
    print("="*80)

    collector = ArbeitsagenturCollector()

    total_jobs_fetched = 0
    total_jobs_stored = 0
    failed_searches = []

    print(f"\nüîç Processing {len(combinations)} unique keyword+location combinations")
    print(f"üìÖ Fetching jobs from last 30 days")
    print(f"‚è±Ô∏è  Estimated time: {len(combinations) * 2} seconds (~2s per search)")
    print()

    start_time = time.time()

    for idx, ((keyword, location), user_ids) in enumerate(combinations.items(), 1):
        print(f"\n[{idx}/{len(combinations)}] {keyword} in {location}")
        print(f"   Used by {len(user_ids)} user(s): {user_ids}")

        try:
            # Search Arbeitsagentur for this combination
            # Use 30 days since posted (but API might round to nearest safe value)
            result = collector.search_jobs(
                keywords=keyword,
                location=location,
                days_since_posted=30,  # Last 30 days
                page_size=100,  # Max results per page
                page=1
            )

            if not result.get('success'):
                print(f"   ‚ùå Search failed: {result.get('message', 'Unknown error')}")
                failed_searches.append((keyword, location, result.get('message')))
                continue

            jobs = result.get('stellenangebote', [])
            total_results = result.get('maxErgebnisse', 0)

            print(f"   üìä Found {total_results} total results, fetched {len(jobs)}")

            # Parse and store jobs
            stored_count = 0
            for job_data in jobs:
                try:
                    parsed_job = collector.parse_job(job_data)
                    if parsed_job:
                        job_db.add_job(parsed_job)
                        stored_count += 1
                except Exception as e:
                    print(f"      ‚ö†Ô∏è  Error storing job: {e}")
                    continue

            total_jobs_fetched += len(jobs)
            total_jobs_stored += stored_count

            print(f"   ‚úÖ Stored {stored_count}/{len(jobs)} jobs")

            # Rate limiting - be nice to the API
            time.sleep(0.5)

        except Exception as e:
            print(f"   ‚ùå Error: {e}")
            failed_searches.append((keyword, location, str(e)))
            continue

    elapsed_time = time.time() - start_time

    print("\n" + "="*80)
    print("BULK LOAD SUMMARY")
    print("="*80)
    print(f"\nüìä Statistics:")
    print(f"   Combinations processed: {len(combinations)}")
    print(f"   Jobs fetched: {total_jobs_fetched}")
    print(f"   Jobs stored: {total_jobs_stored}")
    print(f"   Failed searches: {len(failed_searches)}")
    print(f"   Time elapsed: {elapsed_time:.1f} seconds")
    print(f"   Average per search: {elapsed_time/len(combinations):.2f}s")

    if failed_searches:
        print(f"\n‚ùå Failed Searches ({len(failed_searches)}):")
        for keyword, location, error in failed_searches[:10]:
            print(f"   - {keyword} in {location}: {error}")
        if len(failed_searches) > 10:
            print(f"   ... and {len(failed_searches) - 10} more")

    print("\n‚úÖ Bulk load complete!")
    print("="*80 + "\n")

def main():
    """Main execution"""
    # Parse command-line arguments
    parser = argparse.ArgumentParser(description='Bulk load jobs from Arbeitsagentur')
    parser.add_argument('--yes', '-y', action='store_true',
                       help='Auto-confirm all prompts (for non-interactive execution)')
    args = parser.parse_args()

    print("\n" + "="*80)
    print("ARBEITSAGENTUR BULK LOADER")
    print("="*80)
    print("\nThis script will:")
    print("1. Aggregate all keyword+location combinations from all users")
    print("2. Fetch jobs from Arbeitsagentur for each combination (last 30 days)")
    print("3. Store all jobs in the database")
    print("\nThis is a ONE-TIME operation to populate your job database.")
    print("="*80)

    # Confirm
    if args.yes:
        print("\n‚ö†Ô∏è  Auto-confirmed (--yes flag)")
    else:
        confirm = input("\n‚ö†Ô∏è  Proceed with bulk load? (yes/no): ").strip().lower()
        if confirm != 'yes':
            print("\n‚ùå Bulk load cancelled.")
            return

    # Initialize database
    print("\nüîß Initializing database...")
    job_db = get_database()  # Auto-detects PostgreSQL or SQLite

    # Initialize CV Manager
    if hasattr(job_db, 'connection_pool'):
        # PostgreSQL
        cv_manager = PostgresCVManager(job_db.connection_pool)
        print("‚úì Using PostgreSQL (Railway production database)")
    else:
        # SQLite
        db_path = os.getenv('DATABASE_PATH', 'data/jobs.db')
        cv_manager = CVManager(db_path)
        print("‚úì Using SQLite (local database)")

    # Get all combinations
    combinations = get_all_user_combinations(cv_manager)

    if not combinations:
        print("\n‚ùå No user combinations found. Make sure users have search preferences set.")
        return

    # Show summary and confirm again
    print(f"\nüìä Ready to fetch jobs for {len(combinations)} combinations")
    if args.yes:
        print("‚ö†Ô∏è  Auto-confirmed (--yes flag)")
    else:
        confirm2 = input("‚ö†Ô∏è  This may take several minutes. Continue? (yes/no): ").strip().lower()
        if confirm2 != 'yes':
            print("\n‚ùå Bulk load cancelled.")
            return

    # Bulk load
    bulk_load_jobs(combinations, job_db)

    print("\nüéâ All done! Check your database for new jobs.")

if __name__ == '__main__':
    main()
